# ViT - Vision Transformer

### 1. Introduction

The paper is named 'An Image is Worth 16x16 words: Transformers for Image Recognition as Scale'  and published on ICLR2021 by Google Brain team. 

##### 1.1 Abstraction

- Transformer has become the de-facto standard for natural language processing tasks, but limit in computer vision tasks
- In computer vision attention is is more like a supplement
- ViT achieves a good performance on image classification tasks
- After trained on lager datasets ViT can achieve a comparable performance with SOTA CNN



### 2. Transformers

coming soon





### 3. ViT

coming soon









 
